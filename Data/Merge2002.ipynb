{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30acc6b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Loading Base Dataset ---\n",
      "Loaded base CDS-Family data. Shape: (3411, 5565)\n",
      "\n",
      "--- Merging Longitudinal TAS Data ---\n",
      "-> Merging TAS 2005 data...\n",
      "   Merge complete. New shape: (3418, 6524)\n",
      "-> Merging TAS 2015 data...\n",
      "   Merge complete. New shape: (3425, 7828)\n",
      "\n",
      "--- Generating Final Longitudinal Output Files ---\n",
      "Full longitudinal panel dataset saved to: C:\\Users\\joshu\\Aussie\\Monash\\Parental\\Data\\Analysis Files\\cds_longitudinal_tas_panel.csv\n",
      "Random sample of 1000 observations saved to: C:\\Users\\joshu\\Aussie\\Monash\\Parental\\Data\\Analysis Files\\sample_longitudinal_tas_panel.csv\n"
     ]
    }
   ],
   "source": [
    "# merge_family_data.py\n",
    "#\n",
    "# Purpose:\n",
    "# This script performs the second major step in the data assembly process. It takes the\n",
    "# clean, pre-compiled CDS dataset (created by 'create_cds_dataset.py') and enriches it\n",
    "# by merging the 2001 PSID Main Family File. This adds a comprehensive set of\n",
    "# household-level economic and social variables to each child's record. The final\n",
    "# output is a complete dataset ready for analysis, along with a random sample.\n",
    "#\n",
    "# (Future prompts to modify this code will also be documented in this comprehensive manner)\n",
    "#\n",
    "# Author: Gemini\n",
    "# Date: September 23, 2025\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "# Set a random seed for reproducible sampling\n",
    "np.random.seed(42)\n",
    "\n",
    "def merge_psid_family_data():\n",
    "    \"\"\"\n",
    "    Loads the clean CDS dataset and the 2001 Family file, merges them,\n",
    "    and returns the final, enriched DataFrame.\n",
    "    \"\"\"\n",
    "    # --- Configuration: Set file paths ---\n",
    "    cds_clean_path = r'C:\\Users\\joshu\\Aussie\\Monash\\Parental\\Data\\Supplemental Studies\\Child Development Survey\\CDS2002\\full_merged_cds_data_clean.csv'\n",
    "    family_file_path = r'C:\\Users\\joshu\\Aussie\\Monash\\Parental\\Data\\Main Study\\Family Files\\fam2001er\\FAM2001ER.csv'\n",
    "\n",
    "    try:\n",
    "        print(\"--- Loading Input Files ---\")\n",
    "        # Load the clean, merged CDS data created by the first script\n",
    "        cds_df = pd.read_csv(cds_clean_path)\n",
    "        print(f\"Loaded clean CDS data. Shape: {cds_df.shape}\")\n",
    "\n",
    "        # Load the 2001 PSID Family File\n",
    "        # The codebook confirms 'ER17002' is the 2001 Family Interview ID. We rename it for the merge.\n",
    "        family_df = pd.read_csv(family_file_path, low_memory=False).rename(columns={'ER17002': 'ID_2001'})\n",
    "        print(f\"Loaded 2001 Family File. Shape: {family_df.shape}\")\n",
    "\n",
    "    except FileNotFoundError as e:\n",
    "        print(f\"Error: Could not find a required file. {e}\")\n",
    "        print(\"Please ensure you have run 'create_cds_dataset.py' first and that both file paths are correct.\")\n",
    "        return None\n",
    "\n",
    "    # --- Perform the Merge ---\n",
    "    print(\"\\n--- Merging Family Data ---\")\n",
    "    # We merge the family data onto the CDS data using the 2001 Family ID ('ID_2001'),\n",
    "    # which is common to both files.\n",
    "    final_df = pd.merge(cds_df, family_df, on='ID_2001', how='left', suffixes=('', '_fam2001'))\n",
    "    \n",
    "    # Final structural cleaning to remove any new duplicate columns\n",
    "    final_df = final_df.loc[:, ~final_df.columns.duplicated()]\n",
    "    print(f\"Merge complete. Final dataset shape: {final_df.shape}\")\n",
    "    \n",
    "    return final_df\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    final_enriched_df = merge_psid_family_data()\n",
    "\n",
    "    if final_enriched_df is not None:\n",
    "        # Define the output directory\n",
    "        output_dir = r'C:\\Users\\joshu\\Aussie\\Monash\\Parental\\Data\\Analysis Files'\n",
    "        if not os.path.exists(output_dir):\n",
    "            os.makedirs(output_dir)\n",
    "            \n",
    "        print(\"\\n--- Generating Final Output Files ---\")\n",
    "\n",
    "        # Save the full, enriched dataset\n",
    "        full_output_filename = os.path.join(output_dir, 'full_merged_cds_with_family_data.csv')\n",
    "        final_enriched_df.to_csv(full_output_filename, index=False)\n",
    "        print(f\"Full enriched dataset saved to: {full_output_filename}\")\n",
    "\n",
    "        # Save the random sample\n",
    "        if len(final_enriched_df) >= 1000:\n",
    "            sample_df = final_enriched_df.sample(n=1000)\n",
    "            sample_output_filename = os.path.join(output_dir, 'sample_merged_cds_with_family_data.csv')\n",
    "            sample_df.to_csv(sample_output_filename, index=False)\n",
    "            print(f\"Random sample of 1000 observations saved to: {sample_output_filename}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc34be81",
   "metadata": {},
   "outputs": [],
   "source": [
    "# merge_family_data.py\n",
    "#\n",
    "# Purpose:\n",
    "# This script builds a longitudinal panel dataset by merging the Transition to Adulthood\n",
    "# Supplement (TAS) data onto the clean, compiled CDS-Family dataset. It starts with the\n",
    "# 2002 childhood baseline and adds data from subsequent TAS waves, creating a wide-format\n",
    "# dataset that tracks individuals over time.\n",
    "#\n",
    "# (Future prompts to modify this code will also be documented in this comprehensive manner)\n",
    "#\n",
    "# Author: Gemini\n",
    "# Date: September 23, 2025\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "# Set a random seed for reproducible sampling\n",
    "np.random.seed(42)\n",
    "\n",
    "def merge_longitudinal_tas_data():\n",
    "    \"\"\"\n",
    "    Loads the foundational CDS-Family dataset and sequentially merges TAS data waves.\n",
    "    The function is designed to be easily extendable to include more TAS years.\n",
    "    \n",
    "    Returns:\n",
    "        pandas.DataFrame: A single, wide-format longitudinal DataFrame, or None if errors occur.\n",
    "    \"\"\"\n",
    "    # --- Configuration: Define all file paths ---\n",
    "    # The base file created by the first script ('create_cds_dataset.py')\n",
    "    base_file_path = r'C:\\Users\\joshu\\Aussie\\Monash\\Parental\\Data\\Analysis Files\\full_merged_cds_with_family_data.csv'\n",
    "\n",
    "    # This dictionary controls the merging of TAS files.\n",
    "    # To add more years (e.g., 2007, 2009), simply add a new entry.\n",
    "    # The keys are the year suffixes, and the values are tuples containing:\n",
    "    #   1. The full path to the data file.\n",
    "    #   2. The name of the 1968 Family ID column in that file.\n",
    "    #   3. The name of the Person Number column in that file.\n",
    "    tas_files_to_merge = {\n",
    "        '05': (\n",
    "            r'C:\\Users\\joshu\\Aussie\\Monash\\Parental\\Data\\Supplemental Studies\\Transition into Adulthood Supplement\\ta2005\\TA2005.csv',\n",
    "            'TA050004',\n",
    "            'TA050005'\n",
    "        ),\n",
    "        '15': (\n",
    "            r'C:\\Users\\joshu\\Aussie\\Monash\\Parental\\Data\\Supplemental Studies\\Transition into Adulthood Supplement\\ta2015\\TA2015.csv',\n",
    "            'TA150004',\n",
    "            'TA150005'\n",
    "        )\n",
    "    }\n",
    "\n",
    "    try:\n",
    "        print(\"--- Loading Base Dataset ---\")\n",
    "        # Load the clean, merged CDS-Family data created previously\n",
    "        longitudinal_df = pd.read_csv(base_file_path, low_memory=False)\n",
    "        print(f\"Loaded base CDS-Family data. Shape: {longitudinal_df.shape}\")\n",
    "    except FileNotFoundError:\n",
    "        print(f\"Error: Base file not found at '{base_file_path}'\")\n",
    "        print(\"Please ensure you have run 'create_cds_dataset.py' and the 'merge_family_data.py' (original version) first.\")\n",
    "        return None\n",
    "\n",
    "    # --- Sequentially Merge Each TAS Wave ---\n",
    "    print(\"\\n--- Merging Longitudinal TAS Data ---\")\n",
    "    for year_suffix, (filepath, id_col, pn_col) in tas_files_to_merge.items():\n",
    "        try:\n",
    "            print(f\"-> Merging TAS 20{year_suffix} data...\")\n",
    "            tas_df = pd.read_csv(filepath, low_memory=False)\n",
    "\n",
    "            # Rename TAS key columns to match the base dataframe for a clean merge\n",
    "            rename_map = {id_col: 'ER30001', pn_col: 'ER30002'}\n",
    "            tas_df.rename(columns=rename_map, inplace=True)\n",
    "            \n",
    "            # Perform a left merge to keep all original CDS participants\n",
    "            longitudinal_df = pd.merge(\n",
    "                longitudinal_df,\n",
    "                tas_df,\n",
    "                on=['ER30001', 'ER30002'],\n",
    "                how='left',\n",
    "                suffixes=('', f'_tas{year_suffix}') # Add suffix to new columns\n",
    "            )\n",
    "            print(f\"   Merge complete. New shape: {longitudinal_df.shape}\")\n",
    "\n",
    "        except FileNotFoundError:\n",
    "            print(f\"   Warning: TAS file not found at '{filepath}'. Skipping this year.\")\n",
    "        except Exception as e:\n",
    "            print(f\"   An error occurred while merging {filepath}: {e}\")\n",
    "\n",
    "    # Final structural cleaning\n",
    "    longitudinal_df = longitudinal_df.loc[:, ~longitudinal_df.columns.duplicated()]\n",
    "    \n",
    "    return longitudinal_df\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    final_panel_df = merge_longitudinal_tas_data()\n",
    "\n",
    "    if final_panel_df is not None:\n",
    "        # Define the output directory\n",
    "        output_dir = r'C:\\Users\\joshu\\Aussie\\Monash\\Parental\\Data\\Analysis Files'\n",
    "        if not os.path.exists(output_dir):\n",
    "            os.makedirs(output_dir)\n",
    "            \n",
    "        print(\"\\n--- Generating Final Longitudinal Output Files ---\")\n",
    "\n",
    "        # Save the full, enriched panel dataset\n",
    "        full_output_filename = os.path.join(output_dir, 'cds_longitudinal_tas_panel.csv')\n",
    "        final_panel_df.to_csv(full_output_filename, index=False)\n",
    "        print(f\"Full longitudinal panel dataset saved to: {full_output_filename}\")\n",
    "\n",
    "        # Save the random sample\n",
    "        if len(final_panel_df) >= 1000:\n",
    "            sample_df = final_panel_df.sample(n=1000)\n",
    "            sample_output_filename = os.path.join(output_dir, 'sample_longitudinal_tas_panel.csv')\n",
    "            sample_df.to_csv(sample_output_filename, index=False)\n",
    "            print(f\"Random sample of 1000 observations saved to: {sample_output_filename}\")\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
